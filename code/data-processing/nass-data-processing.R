# setup chunk ####
library(rnassqs)
library(dplyr)
library(ggplot2)
library(tidyr)
library(reshape2)
library(caret)

api_key <- as.character(read.csv("code/NASS_API_key.csv", header = F)[1,1])       # api key
# Specify the range of years across which you want to collect data
years <- as.list(2000:2016)  # BM: Future self, when update with newer data: consider which years to use to minimize 
# the confounding effect of improvements in maize genetics, i.e., shift the
# 16 year window forward, drop oldest records.

# Call in all corn yield data via NASS API ####

nassqs_auth(key = api_key)

## Yields

d <- plyr::ldply(years, function(x){
  
  params <- list(
    commodity_desc = "CORN",
    util_practice_desc = "GRAIN",
    year = x,
    agg_level_desc = "COUNTY", 
    source_desc = "SURVEY",  # change source to source_desc
    domain_desc = "TOTAL"
  )
  
  return(
    nassqs_yields(params) %>%
      filter(
        prodn_practice_desc == "ALL PRODUCTION PRACTICES",
        county_ansi != ""
      ) %>%
      mutate(
        GEOID = paste(state_ansi, county_ansi, sep = ""),
        Yield_mg_ha = as.numeric(Value) * 0.0628
      ) %>%
      dplyr::select(
        year,
        GEOID,
        state_alpha,
        state_ansi,
        county_ansi,
        county_name,
        Yield_mg_ha
      )
  )
})

#ATR addition: write the pulled nass data as it's own data file so we no longer have to pull it every time
write_rds(d, path = "data/nass_03142023.rds")

## ATR: From here we can start with read_rds("data/nass_03142023.rds")

#Dan's code:
### Total acres

census.years <- as.list(c(1997,2002,2007,2012))

d.acres.total <- plyr::ldply(census.years, function(x) {
  
  params <- list(
    commodity_desc = "CORN",
    util_practice_desc = "GRAIN",
    source_desc = "CENSUS",
    year = x,
    agg_level_desc = "COUNTY",
    short_desc = "CORN, GRAIN - ACRES HARVESTED",
    domain_desc = "TOTAL"
  )
  
  return(
    nassqs(params) %>%
      filter(county_ansi != "") %>%
      mutate(
        GEOID = paste(state_ansi, county_ansi, sep = ""),
        Acres_total = as.numeric(gsub(
          Value, pattern = ",", replacement = ""
        ))
      ) %>%
      dplyr::select(
        year,
        GEOID,
        state_alpha,
        state_ansi,
        county_ansi,
        county_name,
        Acres_total
      )
  )
})

#ATR: The next two steps are not needed if we are running the data without removing the irrigated land

##### IRRIGATED ACRES

d.acres.irrigated <- plyr::ldply(census.years, function(x) {
  
  params <- list(
    commodity_desc = "CORN",
    util_practice_desc = "GRAIN",
    source_desc = "CENSUS",
    year = x,
    agg_level_desc = "COUNTY",
    short_desc = "CORN, GRAIN, IRRIGATED - ACRES HARVESTED",
    domain_desc = "TOTAL"
  )
  
  return(
    nassqs(params) %>%
      filter(county_ansi != "") %>%
      mutate(
        GEOID = paste(state_ansi, county_ansi, sep = ""),
        Acres_irrigated = as.numeric(gsub(
          Value, pattern = ",", replacement = ""
        ))
      ) %>%
      dplyr::select(
        year,
        GEOID,
        state_alpha,
        state_ansi,
        county_ansi,
        county_name,
        Acres_irrigated
      )
  )
})

## ATR: This creates a percentage of irrigated land by GEOID

d.acres <- d.acres.total %>%
  left_join(d.acres.irrigated) %>%
  filter(GEOID %in% d$GEOID,!is.na(Acres_total)) %>%
  replace_na(list(Acres_irrigated = 0)) %>%
  mutate(Percent_irrigated = Acres_irrigated / Acres_total) %>%
  group_by(GEOID) %>%
  summarize(
    Mean.percent.irrigated = mean(Percent_irrigated),
    SD.percent.irrigated = sd(Percent_irrigated)
  )

## FILTER BASED ON IRRIGATED ACRES DATA

# Create filter to select counties that are 5 percent or less irrigated, 
# choice of 5 percent based on dsitribution of percentages, vast majority of counties are 5 percent or less irrigated

d.irrgiated.filter <- d.acres %>%
  filter(Mean.percent.irrigated <= 0.05) %>%
  filter(SD.percent.irrigated <= 0.01) 

#ATR to make a data set without filtering the irrigated land we need to repeat this process 
#using the d.acres.total (although a major question is: do we need this step or can we use the d.acres.total by itself?)
#it also look like at this point he filtered to 15 years of corn observations. If we are using cropscape again in the 
#gSSURGO processing2 step do we need this step? 

d <- d %>%
  filter(GEOID %in% d.irrgiated.filter$GEOID) %>% #Filter to counties < 5% irrigated
  group_by(GEOID) %>%
  add_count(GEOID) %>%
  filter(n >= 15) %>% # Filter to >=15 corn yield observations
  ungroup(.) %>%
  dplyr::select(-n)


mod <- function(df){
  df <- df
  
  grid <- expand.grid(span = seq(0.3, 0.5, len = 5), degree = seq(0,1, len=2) )
  
  grid.control <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 5,
    search = "grid")
  
  train_loess <- train(Yield_mg_ha ~ year, 
                       method = "gamLoess",
                       tuneGrid=grid,
                       trControl=grid.control,
                       data = df)
  
  df$Detrend_resids <- as.numeric(residuals(train_loess))
  df$Detrend_predictions <- as.numeric(predict(train_loess))
  return(df)
}


d_list <- split(d, f = d$GEOID)

d_list <- mclapply(X = d_list,FUN = mod, mc.cores = 1)

d <- dplyr::bind_rows(d_list)

d <- d %>%
  group_by(GEOID) %>%
  mutate(County_avg_yield = mean(Yield_mg_ha)) %>%
  ungroup(.) %>%
  mutate(Yield_decomp_add = County_avg_yield+Detrend_resids,  # de-trended yield 
         Yield_decomp_mult = Yield_mg_ha/Detrend_predictions) # yield anomaly


write_rds(d, path = "data/yield_08062020.rds")
